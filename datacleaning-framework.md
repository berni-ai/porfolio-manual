## ðŸ§¼ How Real Data Analysts Clean Data on the Job?

As an analyst, do not chase perfection when prepping data for analysis, aim for clarity, consistency, and data in a *good enough place to analyze, share, and iterate on.*

---

## ðŸšŠ The TRACE Framework
A practical 5-step framework to clean complex data. 

| Step | Description |
|------|-------------|
| **T â€“ Tag issues** | Eyeball for obvious issues: missing values, inconsistencies, outliers, and variations of duplicate|
| **R â€“ Review structure** | Understand what each row represents, explore schema, and map columns to business context |
| **A â€“ Amend selectively** | Clean new columns without overwriting the original sourceâ€”preserve raw data integrity |
| **C â€“ Check for conflicts** | Surface unsolvable issues like nulls, timestamp anomalies, and business logic violations |
| **E â€“ Establish documentation** | Log all identified issues and evaluate their magnitude.|

## ðŸ“¦ Project Context: The Gamezone Dataset

**Gamezone** is a fictional yet business-relevant company that sells new and refurbished gaming products across multiple platforms.

- ðŸŒ Global reach since 2018  
- ðŸ•¹ Omnichannel presence: website, mobile app, and diverse marketing campaigns  
- ðŸŽ¯ Dataset includes user journeys, purchases, product metadata, shipping details, and engagement metrics

---

## ðŸ”TRA = Discovery Steps
1. **Missing Values & Inconsistences**  
- Avoid imputation unless justifiedâ€”it can introduce bias.
- Check for inconsistent categories (e.g. `"XBOX"` vs `"Xbox"`)
- Identify near-duplicates and format mismatches
- Spot nonsensical entries.
2. **Outliers**  
- Investigate before removing. Outliers might reflect real user behavior or valid edge cases.
3. **Business Logic Violations**  
- Example: Shipping before purchase. Flag and surface these in your insightsâ€”they often require stakeholder input.
4. **Nulls Without Source of Truth**  
- Document clearly and exclude from any critical analysis that requires certainty.
5. **Duplicates**  
- Identify and handle all variations of duplicates â€” exact, fuzzy (near-duplicates) and structural, especially across integrated systems.

---

## ðŸ§  CE = Validation Steps
1. **Replicate Before You Modify**  
- Always create a copy of the original dataset before applying changes.

2. **Use Suffixes**  
- Label transformed columns with `_cleaned` or similar. Never overwrite raw columns.

3. **Log the Issues**  
- Maintain detailed logs or comments. They reflect analytical rigor and support team visibility.
  
   **ðŸ“‹ Sample Issue Log Format**

   | Table  | Column       | Issue                        | Row Count | Solvable? | Resolution                 |
   |--------|--------------|------------------------------|-----------|-----------|----------------------------|
   | orders | ship_date    | Missing values               | 627       | No        | Flag as incomplete         |
   | orders | purchase_ts  | Ship date before purchase    | 48        | Yes       | Flag for review            |
   | orders | country_code | Inconsistent format          | 2,194     | Yes       | Standardise to ISO format  |

---
## ðŸ“Œ Rule of Thumb

> If fewer than ~20% of rows are affected by an unsolvable issue. **Document it, flag it, and analyse.**

---

## ðŸ’¡ Analyst Mindset Tips

Good analysts focus on clarityâ€”not perfection. Here are a few mindset principles that guide scalable, thoughtful work:

- Donâ€™t chase perfectionâ€”**chase clarity**
- Prioritise **traceability** and **repeatability**
- Surface **uncertainty** in your insights
- Show your **thought process** through logs and notebooks

---

## ðŸ§  Final Thoughts

Before jumping into analysis, ask yourself. **What story does this data help me tell?**
Ensure you have conceptualised the data to be able to identify the key metrics and dimensions that support real business questions.

---
